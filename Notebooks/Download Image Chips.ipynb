{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Imagery\n",
    "\n",
    "There are two options for downloading imagery: tasks, and local download. Tasks are better for large areas, local download is better for small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, inspect, logging, json, importlib\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "from rasterio.profiles import DefaultGTiffProfile\n",
    "from gbdxtools import Interface\n",
    "from gbdxtools import CatalogImage\n",
    "from shapely.geometry import box\n",
    "\n",
    "cmd_folder = os.path.dirname(os.getcwd())\n",
    "if cmd_folder not in sys.path:\n",
    "    sys.path.insert(0, cmd_folder)\n",
    "\n",
    "from GOST_GBDx_Tools import gbdxTasks\n",
    "from GOST_GBDx_Tools import gbdxURL_misc\n",
    "\n",
    "#In order for the interface to be properly authenticated, follow instructions here:\n",
    "#   http://gbdxtools.readthedocs.io/en/latest/user_guide.html\n",
    "#   For Ben, the .gbdx-config file belongs in C:\\Users\\WB411133 (CAUSE no one else qill f%*$&ing tell you that)\n",
    "gbdx = Interface()\n",
    "gbdx.s3.info\n",
    "curTasks = gbdxTasks.GOSTTasks(gbdx)\n",
    "gbdxUrl = gbdxURL_misc.gbdxURL(gbdx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if imagery is ordered\n",
    "\n",
    "For catids that are not ordered (location: not_delivered), remove them from the list of catIDs in the next cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'acquisition_id': '1020010034A86700', 'state': 'delivered', 'location': 's3://receiving-dgcs-tdgplatform-com/011135131010_01_003'}]\n",
      "[{'acquisition_id': '102001002B6D3A00', 'state': 'delivered', 'location': 's3://receiving-dgcs-tdgplatform-com/011135132010_01_003'}]\n",
      "[{'acquisition_id': '10400100029E0100', 'state': 'delivered', 'location': 's3://receiving-dgcs-tdgplatform-com/011164197010_01_003'}]\n",
      "[{'acquisition_id': '103001002F8E8300', 'state': 'delivered', 'location': 's3://receiving-dgcs-tdgplatform-com/011164198010_01_003'}]\n"
     ]
    }
   ],
   "source": [
    "catIDs = ['1020010034A86700','102001002B6D3A00','10400100029E0100','103001002F8E8300']\n",
    "inAOI = r\"C:\\temp\\hti_aoi.shp\"\n",
    "outExtents = inAOI.replace(\".shp\", \"_imageryExtents.csv\")\n",
    "outFolder = inAOI.replace(\".shp\", \"\")\n",
    "\n",
    "inputAOI = gpd.read_file(inAOI)\n",
    "if not os.path.exists(outFolder):\n",
    "    os.makedirs(outFolder)\n",
    "\n",
    "for c in catIDs:\n",
    "    print(gbdx.ordering.status(gbdx.ordering.order(c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove those that do not exist in the catalog\n",
    "catIDs = ['10400100029E0100','103001002F8E8300']\n",
    "allVals = []\n",
    "for c in catIDs:\n",
    "    img = CatalogImage(c)\n",
    "    allVals.append([c, box(*img.bounds)])\n",
    "res = pd.DataFrame(allVals, columns=['catID','geometry'])\n",
    "res.to_csv(outExtents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the extents are good and area being extracted is not too large, download results\n",
    "catIDs = ['10400100029E0100','103001002F8E8300']\n",
    "for catID in catIDs:\n",
    "    tempImg = CatalogImage(catID, pansharpen=True, acomp=True, dra=True)\n",
    "    chip_image = tempImg.aoi(wkt=str(inputAOI['geometry'].iloc[0]))\n",
    "    image_path = os.path.join(outFolder, \"%s.tif\" % catID)\n",
    "    #This is an arbitrary size assessment\n",
    "    if (chip_image.shape[1] * chip_image.shape[2] < 1000000000000) and not os.path.exists(image_path): \n",
    "        # Save output image to file\n",
    "        cProfile = DefaultGTiffProfile(count=chip_image.shape[0], width=chip_image.shape[2], height=chip_image.shape[1],\n",
    "                                      transform=chip_image.affine, crs={'init':'epsg:4326'})\n",
    "        cProfile.update(dtype=chip_image.dtype)\n",
    "\n",
    "        with rasterio.open(image_path, 'w', **cProfile) as out_raster:\n",
    "            out_raster.write(chip_image)\n",
    "\n",
    "        with open(os.path.join(outFolder, \"%s_metadata.json\" % catID), 'w') as out:\n",
    "            json.dump(tempImg.metadata, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Download\n",
    "\n",
    "This is for large image downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(gbdxTasks)\n",
    "\n",
    "catID = '103001002F8E8300'\n",
    "outS3Folder = 'bps/HTI/Clara/%s' % catID\n",
    "cImg = CatalogImage(catID)\n",
    "download_task = gbdxTasks.GOSTTasks(gbdx)\n",
    "\n",
    "sensor = download_task.sensorDict[cImg.metadata['image']['sensorAlias']]\n",
    "download_workflow = download_task.createWorkflow(catID, str(inputAOI.unary_union), sensor, outS3Folder,\n",
    "                                                 downloadImages=1,\n",
    "                                                 aopPan=False, \n",
    "                                                 aopDra=False, \n",
    "                                                 aopAcomp = True, \n",
    "                                                 aopBands='Auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the workflow\n",
    "workflowID = download_workflow.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'running', 'event': 'started'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run this manually to check on the status\n",
    "#gbdxUrl.descWorkflow(workflowID)['state']\n",
    "gbdxUrl.descWorkflow('5233893148454813538')['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section will monitor workflows as the are executing, updates every minute\n",
    "workflow_results = gbdxUrl.monitorWorkflows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a new command that I have not tested before\n",
    "gbdx.s3.download(outS3Folder, localFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the above section is complete, run the following command to generate \n",
    "#    AWS commands to both list and download S3 contents\n",
    "local_folder = \"C:/temp/outFolder\"\n",
    "if not os.path.exists(local_folder):\n",
    "    os.makedirs(local_folder)\n",
    "listCommands = gbdxUrl.listS3Contents(outS3Folder, recursive=True)\n",
    "downloadCommands = gbdxUrl.downloadS3Contents(outS3Folder, local_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(x) for x in listCommands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdx.s3.download(outS3Folder, localFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is possible to use the below command to execute the download, \n",
    "#    but I prefer to do it in the command line\n",
    "# gbdxUrl.executeAWS_file(downloadCommands, \"C:/temp/outFolder/aws_commands.bat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gost)",
   "language": "python",
   "name": "gost"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
